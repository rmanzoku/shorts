# CLAUDE.md

テキストからショート動画を自動生成する CLI ツール「Oslo」の AI エージェント作業ルール。

## 基本原則

- **ルール化の提案:** ユーザーから繰り返し適用すべき指示や汎用的な作業パターンを受け取った場合、その場で対応するだけでなく「CLAUDE.md / Skill / docs にルールとして追加しますか？」とユーザーに確認すること
- OpenAI API / Google Gemini API はコストが発生する。実行前に必ずユーザーに確認する
- 中間ファイル（音声・画像・SRT）が残っていれば再合成で API コールを回避できる
- 日本語テキストの扱いに注意。CJK 検出・助詞ベース分割・文字数推定が必要
- **Chrome 拡張（Claude in Chrome）は導入済み。** `mcp__claude-in-chrome__*` ツールが接続エラーで失敗した場合、WebSearch/WebFetch 等の代替手段に切り替えず、**作業を一旦停止してユーザーに Chrome の起動を促すこと**。画像収集・ペイウォール記事の閲覧など、ブラウザでしかできない作業がある

## プロジェクト構造

```
contes/               # コンテ（Markdown）— Git 管理、連番命名
  001_soka-gakkai.md
  002_next-topic.md
images/               # 画像ライブラリ — Git 管理、連番命名
  001_kokkai.png      # 画像ファイル（PNG/JPG/WEBP）
  001_kokkai.yml      # YAML サイドカーメタデータ
output/               # 生成物（MP4・中間ファイル）— Git 除外
src/oslo/
  cli.py            # Click CLI エントリポイント
  config.py         # AppConfig / VideoConfig / TTSConfig / ImageGenConfig
  conte.py          # コンテ（Markdown）パーサー
  library.py        # 画像ライブラリ管理（メタデータ・検索・Vision API 分析）
  text_processor.py # テキスト解析・シーン分割・字幕チャンキング・画像プロンプト
  tts.py            # OpenAI TTS クライアント
  image_gen.py      # 画像生成クライアント（Gemini/OpenAI 対応・ライブラリ画像対応）
  subtitles.py      # SRT 字幕生成（CJK 対応・文字数重み付きタイミング）
  composer.py       # MoviePy 動画合成（Ken Burns・crossfade・字幕オーバーレイ）
  pipeline.py       # パイプラインオーケストレーター（コンテ/テキスト両対応）
  utils.py          # リトライデコレーター
```

### コンテ命名規則

`NNN_slug.md`（3桁ゼロ埋め + ハイフン区切りスラッグ）

## コスト意識

- `oslo generate` は API 呼び出し前に確認プロンプトを出す（`--yes` でスキップ）
- 1回の生成: TTS × シーン数 + 画像生成 × シーン数（ライブラリ画像使用時はその分削減）
- 画像生成プロバイダー: Gemini（デフォルト）/ OpenAI（`--image-provider openai` で切替）
- 環境変数: `OPENAI_API_KEY`（TTS 必須）+ `GOOGLE_API_KEY`（Gemini 画像生成時必須）
- `oslo library add` は GPT-4o vision API を呼ぶ（`--skip-analysis` でスキップ可能）
- 字幕・合成の調整のみなら `--keep-temp` で中間ファイルを保持し、再合成スクリプトで対応

## 日本語テキスト処理の注意点

- `_is_cjk_dominant()`: テキストの 20% 以上が CJK 文字なら日本語扱い
- 字幕分割: 句読点で分割 → 助詞・接続語で自然な位置に再分割（`_find_jp_break`）
- 語の途中切れ防止: `_JP_BREAK_CHARS`（助詞・活用語尾）の後で切る
- カタカナ長音（ー）や小書き文字（ッ、ャ等）の前では切らない
- 短断片（3文字以下）は前のチャンクに統合（上限 22 文字）
- 文字数ベースの読み上げ速度推定:
  - 字幕タイミング用: 日本語 350 CPM / 英語 150 WPM
  - **TTS実測値: 日本語 約285 CPM**（コンテの尺見積もりにはこちらを使う）

## Codex CLI 利用ルール

コーディング（新規ファイル作成・既存ファイル修正）は `codex exec` に委譲する。MCP は使わない。

- コード実装: `codex exec "<実装指示>"` で生成し、結果をレビューしてからコミット
- レビュー・調査: Claude が直接行う
- テスト実行・lint: Claude が直接行う（`.venv/bin/pytest`, `.venv/bin/ruff`）

## ワークフロー全体像

| # | ステップ | 担当 | Skill |
|---|---------|------|-------|
| 1 | ネタ提供 | 人間 | - |
| 2 | Web調査 | AI | `/research` |
| 3 | 調査レビュー | 人間 | - |
| 4 | コンテ作成 | AI | `/conte` |
| 5 | コンテレビュー | 人間 | - |
| 6 | 動画生成 | AI | `/generate` |
| 7 | 品質レビュー | AI+人間 | `/improve` |
| 8 | アップロード | 人間 | - |

## コンテフォーマット（Markdown）

入力は `.txt`（平文テキスト）と `.md`（コンテ）の2形式に対応。

```markdown
# タイトル

**フック**: 黒背景に大文字で1.5秒表示するテキスト（15文字以内）

## シーン 1
**画像**: 001_kokkai
**ナレーション**: TTS読み上げ・字幕の元テキスト

## シーン 2
**映像**: 映像の説明（AI画像生成の指示になる）
**ナレーション**: ...
```

- `**フック**`: 動画冒頭1.5秒に黒背景+大文字で表示。ナレーション（TTS）は含まない。15文字以内の衝撃的な事実・数字・疑問文が効果的
- `**画像**`: ライブラリ画像のスラッグを指定（API コールなし）
- `**映像**`: AI 画像生成の指示（Gemini Nano Banana / OpenAI で生成）
- `**画像**` と `**映像**` 両方ある場合は `**画像**` が優先
- `**映像**` がない場合はナレーションから自動生成（フォールバック）
- 映像指示にはスタイルプレフィックスと "Do not include any text" が自動付与される

### 画像ライブラリ

`images/` ディレクトリで事前準備した画像を管理。命名規則: `NNN_slug.{拡張子}`

```bash
oslo library add <画像パス>              # 追加（GPT-4o vision で自動タグ付け）
oslo library add <画像パス> --skip-analysis  # 分析スキップ
oslo library list                        # 一覧
oslo library list --tag 政治             # タグフィルタ
oslo library show <slug>                 # 詳細表示
```

YAML サイドカー（`NNN_slug.yml`）にフリータグ・説明文・出典を格納。`/conte` ワークフローで AI がライブラリから適切な画像を選択し `**画像**` フィールドに自動提案する。

### 台本ガイドライン

- です・ます調、読点2つ以内/文
- 合計60〜90秒（TTS実測 ~285 CPM 基準で **約285〜430文字**。400文字以内推奨）
- 偏向・扇動的表現の禁止
- ライブラリ画像（`**画像**: slug`）を最大限活用し、AI画像生成コストを削減する

## TikTok 成長戦略

### 目標
Creator Rewards Program 参加条件: フォロワー1万人 + 月間10万再生 + 動画1分以上

### 2026年アルゴリズム対策
- 視聴完了率 70%以上がバイラル候補の条件
- リウォッチ率 15-20%以上で大幅ブースト
- フォロワーのエンゲージメントが配信の起点（テスト配信 → 拡散）
- アカウント「信頼度スコア」— 一貫したジャンル・投稿頻度が重要

### コンテンツ設計ルール
- 冒頭3秒: フック必須（衝撃的事実・疑問・数字）
- 動画尺: 60〜90秒（1分以上は収益化必須条件）
- 末尾: 問いかけでコメント促進（「あなたはどう思いますか？」等）
- 情報密度: 「保存したくなる」データ・比較・ランキングを意識

### AI生成コンテンツ（AIGC）ポリシー
- Creator Rewards Program 参加可能（meaningful human input が必要）
- コンテ（台本）は人間が作成・レビュー → human input 条件を満たす
- is_aigc: true でAIラベル開示（信頼性確保）
- 投稿頻度: 1日1本以下（mass-produced 判定回避）

### 投稿運用
- 投稿頻度: 週3〜5本
- 投稿時間: 平日18〜22時、土日13〜21時
- ハッシュタグ: 大規模（100万+）+ ニッチ（1万〜50万）を組み合わせ、10個以内

### トピック選定ガイドライン

TikTok はセンシティブなトピックをアルゴリズムで抑制する。トピック選定時に以下を考慮する:

**推奨（低抑制リスク）:**
- 経済の仕組み（税・保険・年金・給与）
- 技術トレンド（AI・宇宙・エネルギー）
- 国際比較（日本 vs 海外の制度）
- 歴史的な意外事実・統計データ
- 生活に直結する制度変更

**要注意（リフレーム推奨）:**
- 特定の政治家名を前面に出す → 政策・制度の解説に転換
- 選挙予測・政党批判 → 仕組み・数字の解説に転換
- 宗教関連トピック → 税制・非課税制度など仕組みの切り口に転換

**避けるべき（高抑制リスク）:**
- 宗教団体への直接的批判・名指し
- 民族・差別に関する議論
- 医療・健康に関する断定的主張

**リフレーム公式:** 「[特定団体/人物] + [批判的論点]」→「[普遍的な仕組み] + [意外な事実]」
- NG: 「宗教法人課税」→ OK: 「知らなかった！日本の非課税制度」
- NG: 「創価学会の影響力」→ OK: 「連立政権が変わると何が変わる？」

**ハッシュタグ安全ルール:**
- 宗教団体名・政治家個人名をハッシュタグに含めない
- 団体固有タグ → 仕組み・制度タグに置き換え（例: `#宗教法人` → `#非課税制度`）
- Tier 1（2-3個）: メガタグ 100万+（`#雑学` `#解説` `#知識`）
- Tier 2（3-4個）: ミドルタグ 10万-100万（`#お金の話` `#税金` `#日本の政治`）
- Tier 3（2-3個）: トピック固有タグ 1万-10万

## 利用可能な Skill

- `/research` — Web調査ワークフロー（調査メモ `.research.md` を出力）
- `/conte` — コンテ作成ワークフロー（調査メモからコンテ `.md` を作成）
- `/generate` — 動画生成ワークフロー（コンテ/テキスト両対応、再合成判断含む）
- `/improve` — 生成済み動画のレビューと改善ワークフロー（ステップ7）
- `/precommit` — コミット前検証（テスト・lint・品質チェック）

## 開発コマンド

```bash
.venv/bin/pytest tests/ -v   # テスト実行
.venv/bin/ruff check src/    # lint
.venv/bin/ruff check tests/  # テストの lint
```
